{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c15ba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: torch-0.3.0.post4-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: torch==1.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch==1.10.0->torchvision) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp27-cp27mu-linux_x86_64.whl \n",
    "!pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192d48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b090939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21f87b93650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch    # Similar to numpy Library\n",
    "import torch.autograd as autograd  # Tape based automatic diffrentiation library\n",
    "import torch.nn as nn    # Imp library to work on NN\n",
    "import torch.optim as optim  # Torch optimization Library\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939567fd",
   "metadata": {},
   "source": [
    "# Creating Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "688c4995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "tensor([1., 2., 3.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[10., 11., 12.],\n",
      "         [13., 14., 15.],\n",
      "         [16., 17., 18.]],\n",
      "\n",
      "        [[19., 20., 21.],\n",
      "         [22., 23., 24.],\n",
      "         [25., 26., 27.]]])\n",
      "tensor([[[[ 3.3737e-01, -1.7778e-01, -3.0353e-01],\n",
      "          [-5.8801e-01,  3.4861e-01,  6.6034e-01],\n",
      "          [-2.1964e-01, -3.7917e-01,  7.6711e-01]],\n",
      "\n",
      "         [[-1.1925e+00,  6.9835e-01, -1.4097e+00],\n",
      "          [ 1.7938e-01,  1.8951e+00,  4.9545e-01],\n",
      "          [ 2.6920e-01, -7.7020e-02, -1.0205e+00]],\n",
      "\n",
      "         [[-1.6896e-01,  9.1776e-01,  1.5810e+00],\n",
      "          [ 1.3010e+00,  1.2753e+00, -2.0095e-01],\n",
      "          [ 4.9647e-01, -1.5723e+00,  9.6657e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1481e+00, -1.1589e+00,  3.2547e-01],\n",
      "          [-6.3151e-01, -2.8400e+00, -1.3250e+00],\n",
      "          [ 1.7843e-01, -2.1338e+00,  1.0524e+00]],\n",
      "\n",
      "         [[-3.8848e-01, -9.3435e-01, -4.9914e-01],\n",
      "          [-1.0867e+00,  8.8054e-01,  1.5542e+00],\n",
      "          [ 6.2662e-01, -1.7549e-01,  9.8284e-02]],\n",
      "\n",
      "         [[-9.3507e-02,  2.6621e-01, -5.8504e-01],\n",
      "          [ 8.7684e-01,  1.6221e+00, -1.4779e+00],\n",
      "          [ 1.1331e+00, -1.2203e+00,  1.3139e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0533e+00,  1.3881e-01,  2.2473e+00],\n",
      "          [-8.0364e-01, -2.8084e-01,  7.6968e-01],\n",
      "          [-6.5956e-01, -7.9793e-01,  1.8383e-01]],\n",
      "\n",
      "         [[ 2.2935e-01,  5.1463e-01,  9.9376e-01],\n",
      "          [-2.5873e-01, -1.0826e+00, -4.4382e-02],\n",
      "          [ 1.6236e+00, -2.3229e+00,  1.0878e+00]],\n",
      "\n",
      "         [[ 6.7155e-01,  6.9330e-01, -9.4872e-01],\n",
      "          [-7.6507e-02, -1.5264e-01,  1.1674e-01],\n",
      "          [ 4.4026e-01, -1.4465e+00,  2.5529e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.4963e-01,  1.0042e+00,  8.2723e-01],\n",
      "          [-3.9481e-01,  4.8923e-01, -2.1681e-01],\n",
      "          [-1.7472e+00, -1.6025e+00, -1.0764e+00]],\n",
      "\n",
      "         [[ 9.0315e-01, -7.2184e-01,  1.2311e+00],\n",
      "          [-1.0973e+00, -9.6690e-01,  6.7125e-01],\n",
      "          [-9.4053e-01, -4.6806e-01,  1.0322e+00]],\n",
      "\n",
      "         [[-2.8300e-01,  1.1124e+00, -4.1684e-01],\n",
      "          [-1.7106e+00, -3.2902e-01,  1.3966e+00],\n",
      "          [-9.9491e-01, -1.5822e-03,  1.2471e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a torch.Tensor object from python list\n",
    "v = [1, 2, 3]\n",
    "print(type(v))\n",
    "v_tensor = torch.Tensor(v)\n",
    "print(v_tensor)\n",
    "\n",
    "# Create a torch.Tensor object of size 2x3 from 2x3 matrix\n",
    "m2x3 = [[1, 2, 3], [4, 5, 6]]\n",
    "m2x3_tensor = torch.Tensor(m2x3)\n",
    "print(m2x3_tensor)\n",
    "\n",
    "# Create a 3D torch.Tensor object of size 3x3x3.\n",
    "m3x3x3 = [[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "          [[10, 11, 12],[13, 14, 15], [16, 17, 18]],\n",
    "            [[19, 20, 21],[22, 23, 24], [25, 26, 27]]]\n",
    "m3x3x3_tensor = torch.Tensor(m3x3x3)\n",
    "print(m3x3x3_tensor)\n",
    "\n",
    "#Create a 4Dtensor from random data and given dimensions (in this case 3x4x5x6) with torch.randn()\n",
    "m4x3x3x3_tensor = torch.randn((4, 3, 3, 3))\n",
    "m4x3x3x3_tensor.shape\n",
    "print(m4x3x3x3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3c1cb",
   "metadata": {},
   "source": [
    "## What is a multidimensional tensor?\n",
    "Since we frequently deal with n > 3 dimensional tensors, its understanding is very important. The best way to think of a higher (n) dimensional object (and tensor in particular) is as of a container which keeps a series of n-1 dimensional objects \"inside\" of it. We can \"pull out\" these \"inner\" objects by indexing in to higher dimensional tensor container. Let's have a look on some examples:\n",
    "\n",
    "For a vector v (dim(v)=1), indexing into it (\"pulling out of it\") returns its \"slice\" - a scalar s (dim(s)=0).\n",
    "\n",
    "For a matrix, indexing into it returns its \"slice\" - a (row or column) vector.\n",
    "\n",
    "3D tensor can be seen as a cube or 3D rectangular consisting of horizontally \"stacked\" matrices. So if we index into a such tensor it will give us its slice which is a matrix!\n",
    "\n",
    "We can't easily visualize 5D (or n-D) tensors, but the idea is actually the same. If we index in to them, we will pull out an object of dimension n-1.\n",
    "\n",
    "E.g. a 4D tensor can be seen as a list of cubes or 3D reactangulars. If we index in to a 4D tensor, we will get 3D rectangulars.\n",
    "\n",
    "IMG_0120.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9024d2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[[ 0.3374, -0.1778, -0.3035],\n",
      "         [-0.5880,  0.3486,  0.6603],\n",
      "         [-0.2196, -0.3792,  0.7671]],\n",
      "\n",
      "        [[-1.1925,  0.6984, -1.4097],\n",
      "         [ 0.1794,  1.8951,  0.4954],\n",
      "         [ 0.2692, -0.0770, -1.0205]],\n",
      "\n",
      "        [[-0.1690,  0.9178,  1.5810],\n",
      "         [ 1.3010,  1.2753, -0.2010],\n",
      "         [ 0.4965, -1.5723,  0.9666]]])\n"
     ]
    }
   ],
   "source": [
    "# Index into v_tensor and get a scalar\n",
    "print(v_tensor[0])\n",
    "\n",
    "# Index into m2x3_tensor and get a vector\n",
    "print(m2x3_tensor[0])\n",
    "\n",
    "# Index into m3x3x3_tensor and get a matrix\n",
    "print(m3x3x3_tensor[0])\n",
    "\n",
    "# Index into m4x3x3x3_tensor and get a 3D rectangular of size 4x5x6\n",
    "print(m4x3x3x3_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec258e8",
   "metadata": {},
   "source": [
    "## Operations with Tensors\n",
    "You can operate on tensors in the ways you would expect. See the documentation http://pytorch.org/docs/torch.html for a complete list of operations.\n",
    "\n",
    "Simple mathematical operations: Addition, Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac2e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([4., 5., 6.])\n",
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "y = torch.Tensor([4, 5, 6])\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "w = torch.matmul(x, y)    # matmul is a scaler multiplication\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd2fdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5485, -1.6063,  0.7281,  0.6609,  0.2391],\n",
      "        [ 0.0340,  0.1164, -0.9905,  0.5646,  0.0686]])\n",
      "tensor([[-1.0035, -0.7874,  0.9840,  0.2045, -0.3604],\n",
      "        [ 1.2101, -1.0814,  0.0789,  0.2913, -0.5023],\n",
      "        [-0.9306,  0.9086, -0.7788, -1.4453,  0.7636]])\n",
      "tensor([[ 0.5485, -1.6063,  0.7281,  0.6609,  0.2391],\n",
      "        [ 0.0340,  0.1164, -0.9905,  0.5646,  0.0686],\n",
      "        [-1.0035, -0.7874,  0.9840,  0.2045, -0.3604],\n",
      "        [ 1.2101, -1.0814,  0.0789,  0.2913, -0.5023],\n",
      "        [-0.9306,  0.9086, -0.7788, -1.4453,  0.7636]])\n",
      "tensor([[-0.2469,  0.5857,  0.9906,  0.0417, -1.1668],\n",
      "        [ 1.3251, -0.7990,  0.6292, -1.2097, -2.1362]])\n",
      "tensor([[-0.1212, -0.1443,  0.9969,  0.5697, -0.4930],\n",
      "        [ 0.3155, -0.2275, -1.7942,  1.0417, -0.2358]])\n",
      "tensor([[-0.2469,  0.5857,  0.9906,  0.0417, -1.1668, -0.1212, -0.1443,  0.9969,\n",
      "          0.5697, -0.4930],\n",
      "        [ 1.3251, -0.7990,  0.6292, -1.2097, -2.1362,  0.3155, -0.2275, -1.7942,\n",
      "          1.0417, -0.2358]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5485, -1.6063,  0.7281,  0.6609,  0.2391],\n",
       "        [ 0.0340,  0.1164, -0.9905,  0.5646,  0.0686],\n",
       "        [-0.2469,  0.5857,  0.9906,  0.0417, -1.1668],\n",
       "        [ 1.3251, -0.7990,  0.6292, -1.2097, -2.1362]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default, it concatenates along the axis with 0 (rows). It's \"stacking\" the rows.\n",
    "\n",
    "x_1 = torch.randn(2, 5)\n",
    "print(x_1)\n",
    "y_1 = torch.randn(3, 5)\n",
    "print(y_1)\n",
    "z_1 = torch.cat([x_1, y_1])\n",
    "print(z_1)\n",
    "\n",
    "# Concatenate columns:\n",
    "x_2 = torch.randn(2, 5)\n",
    "print(x_2)\n",
    "y_2 = torch.randn(2, 5)\n",
    "print(y_2)\n",
    "# second arg specifies which axis to concat along. Here we select 1 (columns). It's attaching the columns.\n",
    "z_2 = torch.cat([x_2, y_2], 1)\n",
    "print(z_2)\n",
    "\n",
    "# If your tensors are not compatible, torch will complain.  Uncomment to see the error\n",
    "torch.cat([x_1, x_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1829872b",
   "metadata": {},
   "source": [
    "### Remarl: If enter wrong value in row 11 or 13, we will get wrong solution for row 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d6bb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3030,  0.4934, -0.2766,  0.2439, -1.2116],\n",
      "        [-0.1520,  0.1509, -0.6251, -0.4416,  0.3208]])\n",
      "tensor([[-0.3273, -0.5305, -0.0172,  0.4719,  0.5671],\n",
      "        [ 2.7930,  0.3229,  0.8552,  0.7492, -1.7119],\n",
      "        [ 0.6025, -0.7018, -1.3130,  0.1574,  2.0114]])\n",
      "tensor([[-0.3030,  0.4934, -0.2766,  0.2439, -1.2116],\n",
      "        [-0.1520,  0.1509, -0.6251, -0.4416,  0.3208],\n",
      "        [-0.3273, -0.5305, -0.0172,  0.4719,  0.5671],\n",
      "        [ 2.7930,  0.3229,  0.8552,  0.7492, -1.7119],\n",
      "        [ 0.6025, -0.7018, -1.3130,  0.1574,  2.0114]])\n",
      "tensor([[ 0.1004,  0.8222, -0.0176],\n",
      "        [ 1.2481, -0.0710,  2.1627]])\n",
      "tensor([[ 1.5215, -1.0547,  1.7822,  1.9736, -0.3101],\n",
      "        [-0.8211,  0.1315, -0.6948, -0.5823,  1.0035],\n",
      "        [-1.4613,  0.8985,  0.6210, -0.9679,  0.6740]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 2 but got size 3 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c85240a5062e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# second arg specifies which axis to concat along. Here we select 1 (columns). It's attaching the columns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mz_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2 but got size 3 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# By default, it concatenates along the axis with 0 (rows). It's \"stacking\" the rows.\n",
    "\n",
    "x_1 = torch.randn(2, 5)\n",
    "print(x_1)\n",
    "y_1 = torch.randn(3, 5)\n",
    "print(y_1)\n",
    "z_1 = torch.cat([x_1, y_1])\n",
    "print(z_1)\n",
    "\n",
    "# Concatenate columns:\n",
    "x_2 = torch.randn(2, 3)\n",
    "print(x_2)\n",
    "y_2 = torch.randn(3, 5)\n",
    "print(y_2)\n",
    "# second arg specifies which axis to concat along. Here we select 1 (columns). It's attaching the columns.\n",
    "z_2 = torch.cat([x_2, y_2], 1)\n",
    "print(z_2)\n",
    "\n",
    "# If your tensors are not compatible, torch will complain.  Uncomment to see the error\n",
    "torch.cat([x_1, x_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c736ac8",
   "metadata": {},
   "source": [
    "## Reshaping Tensors\n",
    "We can use the .view() method to reshape a tensor. Often we will need to reshape our data before passing it to a neuronal network.\n",
    "\n",
    "Let's assume we have 64000 RGB images with the size of 28x28 pixels. We can define an array fo shape (64000, 3, 28, 28) to hold them, where 3 is number of color channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd91cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(64000, 3, 28, 28)\n",
    "# Now we want to add a batch dimension of size 32. We can then infer the second dimension by placing -1:\n",
    "x_rehsaped = x.view(32, -1, 3, 28, 28)\n",
    "print(x_rehsaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069c892",
   "metadata": {},
   "source": [
    "# Computation Graphs and Automatic Differentiation\n",
    "A computation graph is a specification of what parameters with which operations are involved in the computation to give the output.\n",
    "\n",
    "The fundamental class of Pytorch autograd.Variable keeps track of how it was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e68b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables wrap tensor objects\n",
    "x = autograd.Variable(torch.Tensor([1, 2, 3]), requires_grad=True)\n",
    "# You can access the data with the .data attribute\n",
    "print(x.data)\n",
    "\n",
    "y = autograd.Variable(torch.Tensor([4, 5, 6]), requires_grad=True)\n",
    "\n",
    "# With autograd.Variable you can also perform all the same operations you did with tensors\n",
    "z = x + y\n",
    "print(z.data)\n",
    "\n",
    "#  w knows also that it's result of addition of z lements (AddBackward)\n",
    "operation = z.grad_fn\n",
    "print(operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets sum up all the entries in z\n",
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbfd39",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "    So now, what is the derivative of this sum with respect to the first component of x? Remember, that x is a tensor of 3 elements: $x = (x_0, x_1, x_2)$\n",
    "\n",
    "    In math, we want a partial derivative of $s$ with respect to $x_0$: $\\frac{\\partial s}{\\partial x_0}$\n",
    "\n",
    "    Well, $s$ knows that it was created as a $sum$ of the tensor $z$ elements $(z_0, z_1, z_2)$. $z$ knows that it was the sum $x + y$. So\n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "    And so $s$ contains enough information to determine that the derivative of $s$ with respect to $x_0$ is 1!\n",
    "\n",
    "    Reminder: If you compute the partial derivative with respekt to one variable, you handle all other variables as constants. Therefore they all $(x_1, x_2, y_0, y_1, y_2)$ get zeroes, and the derivative of $f(x_0) = x_0$ is 1.\n",
    "\n",
    "    First we need to run backpropagation and calculate gradients with respect to every variable. Note: if you run backward multiple times, the gradient will increment. That is because Pytorch accumulates the gradient into the .grad property, since for many models this is very convenient. Lets now have Pytorch compute the gradient, and see that we were right with our guess of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling .backward() on any variable will run backprop, starting from it.\n",
    "s.backward(retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0641b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95735545",
   "metadata": {},
   "source": [
    "### How NOT to break the computational graph\n",
    "Let's create two torch tensors and add them up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((2, 2))\n",
    "y = torch.randn((2, 2))\n",
    "z = x + y  # These are Tensor types, and backprop would not be possible\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fd3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_x = autograd.Variable(x, requires_grad=True)\n",
    "var_y = autograd.Variable(y, requires_grad=True)\n",
    "# var_z contains enough information to compute gradients, as we saw above\n",
    "var_z = var_x + var_y\n",
    "print(var_z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_z_data = var_z.data\n",
    "new_var_z = autograd.Variable(var_z_data)\n",
    "print(new_var_z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a779724",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_z.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e2edd",
   "metadata": {},
   "source": [
    "# Cuda\n",
    "Check wether GPU accelaration with CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # creates a LongTensor and transfers it\n",
    "    # to GPU as torch.cuda.LongTensor\n",
    "    a = torch.LongTensor(10).fill_(3).cuda()\n",
    "    print(type(a))\n",
    "    b = a.cpu()\n",
    "    # transfers it to CPU, back to\n",
    "    # being a torch.LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155d714",
   "metadata": {},
   "source": [
    "# Create Linear Model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc846ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(20)] #list comprehention\n",
    "x_train = np.array(x, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "print(x)\n",
    "print(x_train.shape)\n",
    "\n",
    "y = [(5*i + 2) for i in x] #list comprehention\n",
    "y_train = np.array(y, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "print(y)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953005dc",
   "metadata": {},
   "source": [
    "# Create Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressor, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressor(input_dim, output_dim)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a0438",
   "metadata": {},
   "source": [
    "# Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31670875",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "print(optimizer)\n",
    "print(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    #Convert inputs and outputs to torch variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    \n",
    "    real_outputs = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    # Reset Gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward - compute the output\n",
    "    pred_outputs = model(inputs)\n",
    "    \n",
    "    # Loss\n",
    "    loss = loss_function(pred_outputs, real_outputs)\n",
    "    \n",
    "    # Backword - compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('epoch {}, loss {}'.format(epoch, loss.data[0]))\n",
    "    #print('epoch {}, loss {} '. format(epoch, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    #Convert inputs and outputs to torch variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    \n",
    "    real_outputs = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    # Reset Gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward - compute the output\n",
    "    pred_outputs = model(inputs)\n",
    "    \n",
    "    # Loss\n",
    "    loss = loss_function(pred_outputs, real_outputs)\n",
    "    \n",
    "    # Backword - compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('epoch {}, loss {}'.format(epoch, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fade35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
